# Ã†therLight Sprint 18.2_Sprint_2_Bugs (v0.18.5)
# Created: 2025-11-19
# Purpose: Fix critical bugs found during Sprint 18.2 manual testing
# Status: Active

[metadata]
version = "0.18.5"
sprint_number = "18.2.2"
sprint_name = "Sprint 18.2_Sprint_2_Bugs - Critical Bug Fixes"
start_date = "2025-11-19"
target_completion = "2025-11-20"
status = "active"
created = "2025-11-19"

[metadata.focus]
primary = "Fix critical bugs blocking Sprint 18.2 features"
secondary = "Complete Mac support - Terminal fix + Desktop app binaries (.dmg)"
tertiary = "Fix UX issues affecting user experience"
quaternary = "Update documentation for accuracy"
quinary = "Research JEPA for pattern prediction (PoC)"

[metadata.priority_order]
phase_1 = "Critical Bug Fixes - BUG-001, BUG-002 (blocks features)"
phase_2 = "Mac Compatibility - MAC-001 (terminal fix, parallel work)"
phase_3 = "UX Bug Fixes - BUG-003, BUG-004 (improves experience)"
phase_4 = "Build Tasks - BUILD-001 (Mac desktop app binaries)"
phase_5 = "Quality Assurance - QA tasks (stability)"
phase_6 = "Documentation - DOC tasks (completeness)"
phase_7 = "Publishing - PUB tasks (release v0.18.5)"
phase_8 = "Retrospective - RETRO tasks (learning)"
phase_9 = "Research - JEPA tasks (pattern prediction PoC, parallel work)"

[metadata.progression]
previous_sprint = "internal/sprints/SPRINT_18.2_MANUAL_TEST_CHECKLIST.md"
triggers_patch_release = true
git_branch = "fix/sprint-18.2-critical-bugs"

[metadata.audit_context]
test_document = "internal/sprints/SPRINT_18.2_MANUAL_TEST_CHECKLIST.md"
critical_bugs_found = 2
medium_bugs_found = 2
low_issues_found = 3
mac_compatibility_issues = 2
mac_issue_1 = "PowerShell hardcoded in terminal creation (voicePanel.ts:1063) - Breaks on Mac"
mac_issue_2 = "No Mac desktop app binaries (.dmg) - Voice capture unavailable on Mac"

[metadata.mac_support_strategy]
goal = "Achieve full feature parity between Windows and Mac platforms"
status = "In Progress"
phase_1_quick_fix = "MAC-001: Remove PowerShell hardcoding (15-30 min) - Extension works on Mac"
phase_2_voice_capture = "BUILD-001: Build Mac desktop .dmg (4-6 hours) - Voice features work on Mac"
expected_completion = "2-3 days (includes setup, build, testing)"
impact = "Mac users gain full Ã†therLight functionality (terminal + voice capture)"

[metadata.team]
team_size = 1
default_engineer = "BB_Aelor"

[[metadata.team.engineers]]
id = "engineer_1"
name = "BB_Aelor"
expertise = ["typescript", "vscode-extensions", "ui-ux", "toml", "testing", "rust", "tauri", "macos"]
available_agents = ["infrastructure-agent", "ui-agent", "documentation-agent", "testing-agent"]
max_parallel_tasks = 2
daily_capacity_hours = 8

[progress]
total_tasks = 38
completed_tasks = 5
in_progress_tasks = 0
pending_tasks = 33
completion_percentage = 13.2

# ==============================================================================
# FEATURE TASKS - Critical Bug Fixes from Sprint 18.2 Testing
# ==============================================================================

[tasks.BUG-001]
id = "BUG-001"
name = "Fix Sprint TOML parsing error (brackets in templates)"
status = "completed"
phase = "critical-bugfix"
agent = "infrastructure-agent"

why = """
Issue 4 from Sprint 18.2 testing: Sprint TOML parsing fails with brackets in prompt templates.
DISCOVERED DURING ANALYSIS: 10 fields silently dropped by parser, breaking 7 UI features.
User expectation: Sprint panel shows task list, all fields display, enhanced prompts load correctly.
Current state: Extension crashes when loading sprint + missing fields break document links.
Root cause 1: Brackets like <Your text here> in prompt strings interpreted as TOML table headers.
Root cause 2: parseTomlTasks manually assigns only 27 of 40+ fields, dropping skill, enhanced_prompt, questions_doc, etc.
Users cannot use Sprint features OR document features until fixed.
"""

context = """
ISSUE 1 - Bracket Parsing:
TOML parser (@iarna/toml) interprets <text> as table header definition.
Sprint files use enhanced prompt templates with placeholder text.
Example causing crash: prompt = "Enter {Your task details here}"
Parser sees {Your task details here} as new table section.
FIX: Change delimiter from {text} to <text> in all sprint files.

ISSUE 2 - Missing Fields (CRITICAL DISCOVERY):
SprintLoader.ts parseTomlTasks() manually assigns only 27 fields.
TOML schema defines 40+ fields. 10 fields are silently dropped:
1. skill (MVP-001 workflow automation)
2. enhanced_prompt (MVP-003 document path)
3. template (MVP-003 template version)
4. questions_doc (UI-001 questions path)
5. test_plan (UI-001 test plan path)
6. design_doc (UI-001 design path)
7. pattern_reference (pattern doc path)
8. completion_notes (completion details)
9. subtask_progress (progress tracking)
10. condition (conditional execution)

UI references 7 of these fields (enhanced_prompt, template, questions_doc, test_plan, design_doc, pattern_reference, completion_notes) â†’ broken features.
FIX: Implement TOML passthrough using spread operator (...task) for future-proof parsing.

BACKWARDS COMPATIBILITY REQUIREMENTS:
- Old sprint files with {text} syntax must still work (auto-convert with warning)
- New <text> syntax must work on old extension versions (forward compatible)
- New fields ignored by old parsers (graceful degradation)
- Provide migration script: scripts/migrate-sprint-syntax.js
- Non-breaking: Core fields (id, name, status) unchanged

Integration points:
- SprintLoader.ts:513-557 (parseTomlTasks - add 10 fields + spread operator)
- SprintRenderer.ts (add generic field renderer for unknown fields)
- All sprint TOML files with {text} placeholders (~10 files)
- scripts/validate-sprint-schema.js (add <text> detection + migration helper)

Historical: 2025-11-03 bug (2 hours) - Wrong TOML format broke sprint panel
Prevention: Flexible parsing + validation before commit (VAL-001)
"""

reasoning_chain = [
    "1. User opens workspace with Ã†therLight installed",
    "2. Extension activates, loads ACTIVE_SPRINT.toml",
    "3. SprintLoader.parse() calls @iarna/toml parser",
    "4. Parser encounters <Your text> in prompt field",
    "5. Parser throws error: unexpected table header at row X",
    "6. Extension catches error, logs to console",
    "7. Sprint Panel shows empty or error state",
    "8. User cannot access Sprint features"
]

pattern_context = "Pattern-SPRINT-PLAN-001: Sprint file format, Pattern-TASK-ANALYSIS-001: Pre-task analysis"

success_impact = """
After BUG-001 complete:
âœ… Sprint TOML files parse without errors (bracket issue fixed)
âœ… All 10 missing fields now parsed (skill, enhanced_prompt, questions_doc, etc.)
âœ… Sprint Panel loads task list correctly
âœ… Document links work (enhanced_prompt, questions_doc, test_plan buttons functional)
âœ… UI displays all task metadata (no data loss)
âœ… Validation prevents future bracket issues
âœ… Future fields automatically parsed (TOML passthrough implemented)
âœ… Old sprint files still work (backwards compatible)
âœ… Migration script available for bulk updates
âœ… Users can use ALL Sprint features (7 broken features restored)
"""

test_requirements = """
TDD Requirements (Infrastructure Task - 90% coverage):

RED Phase - Write tests FIRST:
1. Sprint with {text} placeholder causes parse error â†’ Document current failure
2. Sprint with escaped placeholders passes validation
3. Sprint with alternative delimiter passes (e.g., {{text}}, <text>)
4. Validation script detects invalid placeholders
5. Pre-commit hook blocks commits with invalid placeholders

GREEN Phase - Implement fix:
Option A: Escape brackets (\\{text\\})
Option B: Change delimiter ({text} â†’ <<text>> or <text>)
Option C: Use different TOML structure (multi-line strings)

REFACTOR Phase - Optimize performance, add comprehensive tests
"""

test_files = [
    "vscode-lumina/test/services/SprintLoader.test.ts",
    "scripts/test/validate-sprint-schema.test.js"
]

test_coverage_requirement = 0.9

validation_criteria = [
    "TOML parser handles template placeholders without errors",
    "SprintLoader.parse() completes successfully",
    "Sprint Panel displays task list",
    "Validation script detects invalid placeholders",
    "Pre-commit hook blocks invalid sprint files",
    "All existing sprint files parse correctly after fix"
]

estimated_lines = 150
estimated_time = "2-3 hours"

files_to_modify = [
    "vscode-lumina/src/services/SprintLoader.ts (lines 292-333 - TOML parsing)",
    "scripts/validate-sprint-schema.js (add placeholder validation)",
    "internal/sprints/*.toml (update all sprint files with placeholders)"
]

deliverables = [
    "Fix TOML parsing to handle template placeholders (change <text> to <text>)",
    "Add 10 missing fields to parseTomlTasks (skill, enhanced_prompt, questions_doc, etc.)",
    "Implement flexible TOML passthrough using spread operator (future-proof)",
    "Add backwards compatibility layer (auto-convert <text> with warning)",
    "Create migration script: scripts/migrate-sprint-syntax.js",
    "Update all sprint files with safe placeholder syntax (~10 files)",
    "Add generic field renderer in UI for unknown fields",
    "Add validation rule to detect <text> and suggest <text>",
    "Test all existing sprint files parse correctly",
    "Verify all 7 broken UI features now work (document links functional)",
    "Document safe placeholder syntax in SPRINT_TEMPLATE_GUIDE.md",
    "Update CLAUDE.md pre-flight checklist with <text> â†’ <text> rule"
]

error_handling = """
- Wrap TOML parse() in try-catch with clear error messages
- Handle parse errors gracefully (don't crash extension)
- Log parse errors with file path and row number
- Show user-friendly error in Sprint Panel if parse fails
- Provide recovery: Skip invalid sprint, show default state
- Add validation before commit to prevent bad TOML reaching users
"""

performance_target = "Sprint file parsing < 100ms"
patterns = ["Pattern-SPRINT-PLAN-001", "Pattern-TASK-ANALYSIS-001", "Pattern-CODE-001"]
dependencies = []

[tasks.BUG-002]
id = "BUG-002"
name = "Fix 'Start This Task' template loading (text area empty)"
status = "completed"
phase = "critical-bugfix"
agent = "ui-agent"

why = """
Issue 8 from Sprint 18.2 testing: "Start This Task" button shows toast but text area remains empty.
User expectation: Click button â†’ Template loads in text area â†’ User reviews â†’ Ctrl+Enter sends.
Current state: Toast appears, terminal opens, but text area empty (template not loaded).
Users cannot use task workflow feature - core functionality broken.
"""

context = """
BUG-009 fix (Sprint 18.2) partially working:
âœ… Toast notification appears correctly
âœ… Terminal opens automatically
âœ… Auto-send prevented (main BUG-009 fix goal achieved)
âŒ Template insertion into text area fails (critical regression)

Message flow:
1. Sprint Panel webview: User clicks "Start This Task" button
2. Sprint Panel sends message to Voice Panel: <type: "loadTaskTemplate", taskId: "TASK-001", template: "...">
3. Voice Panel webview receives message
4. Voice Panel should call insertTaskTemplate(template) to populate text area
5. FAILURE POINT: Text area remains empty

Debugging clues:
- Toast says "template loaded" â†’ Message received by handler
- Text area empty â†’ insertTaskTemplate() not executing or failing silently
- Check: voicePanel.ts:877 (BUG-009 fix location)
- Check: Webview message handler for "loadTaskTemplate" event
"""

reasoning_chain = [
    "1. User opens Sprint Panel, selects task",
    "2. Clicks 'Start This Task' button",
    "3. Sprint Panel webview posts message to Voice Panel",
    "4. Voice Panel receives message, shows toast notification",
    "5. Voice Panel opens terminal (working)",
    "6. Voice Panel should call insertTaskTemplate(template)",
    "7. FAILURE: insertTaskTemplate() not called or fails silently",
    "8. Text area remains empty, user cannot review template",
    "9. User cannot send template (nothing to send)"
]

pattern_context = "Pattern-UX-001: Real-time feedback, Pattern-CODE-001: Code workflow"

success_impact = """
After BUG-002 complete:
âœ… "Start This Task" button fully functional
âœ… Template loads into Voice Panel text area
âœ… User can review template before sending
âœ… Ctrl+Enter sends template to terminal
âœ… Task workflow feature restored
âœ… User satisfaction improved (core feature working)
"""

test_requirements = """
TDD Requirements (UI Task - 70% coverage):

RED Phase - Write tests FIRST:
1. Click "Start This Task" â†’ Toast notification appears
2. Click "Start This Task" â†’ Text area contains task template
3. Template text matches task enhanced prompt
4. Terminal opens automatically
5. Ctrl+Enter sends template to terminal
6. Error handling: Missing template shows friendly error

GREEN Phase - Implement fix:
1. Debug message passing Sprint Panel â†’ Voice Panel
2. Verify insertTaskTemplate() function exists and is called
3. Fix function call if missing or broken
4. Test with multiple task types

REFACTOR Phase - Improve error handling, add logging
"""

test_files = [
    "vscode-lumina/test/commands/voicePanel.test.ts",
    "vscode-lumina/test/webview/sprintPanel.test.ts"
]

test_coverage_requirement = 0.7

validation_criteria = [
    "âœ¨ 'Start This Task' button enabled and clickable",
    "Click triggers template load into text area",
    "Text area contains enhanced prompt template",
    "Toast notification shows success message",
    "Terminal opens automatically",
    "Ctrl+Enter sends template to terminal",
    "Error handling: Missing template shows error message"
]

estimated_lines = 100
estimated_time = "3-4 hours"

files_to_modify = [
    "vscode-lumina/src/commands/voicePanel.ts (lines 877+ - BUG-009 fix, message handler)",
    "vscode-lumina/src/webview/sprintPanel.html (button click handler)",
    "vscode-lumina/src/webview/voicePanel.html (message receiver, insertTaskTemplate function)"
]

deliverables = [
    "Fix message passing Sprint Panel â†’ Voice Panel",
    "Implement or fix insertTaskTemplate() function",
    "Text area populates with task template",
    "Add error handling for missing templates",
    "Add console logging for debugging",
    "Test with multiple tasks to ensure consistency"
]

error_handling = """
- Wrap insertTaskTemplate() in try-catch
- Handle missing template data gracefully
- Handle webview not ready (timing issue)
- Log template loading steps for debugging
- Show user-friendly error if template load fails
- Provide retry mechanism if initial load fails
- Preserve any existing text in text area (don't overwrite user input)
"""

performance_target = "Template insertion < 500ms"
patterns = ["Pattern-UX-001", "Pattern-CODE-001", "Pattern-TDD-001"]
dependencies = []

[tasks.BUG-003]
id = "BUG-003"
name = "Fix welcome message not appearing (FEATURE-004)"
status = "completed"
phase = "ux-bugfix"
agent = "ui-agent"

why = """
Issue 5 from Sprint 18.2 testing: Welcome message doesn't appear on fresh workspace install.
User expectation: First time opening Voice Panel â†’ See welcome message with getting started guide.
Current state: Text area empty, no welcome message, users confused about how to start.
FEATURE-004 marked as implemented but not working.
"""

context = """
FEATURE-004 implementation: Welcome message on first launch.
Expected: "# ðŸš€ Welcome to Ã†therLight v0.18.3!" in Voice Panel text area.
Actual: Text area empty on fresh install.

Potential causes (from testing):
1. 3-second delay too short (voice panel webview not ready)
2. hasSeenWelcome flag incorrectly set to true on first run
3. TOML parsing error (BUG-001) crashing extension before welcome message
4. postWelcomeMessage() function not being called

Debugging needs:
- Check Output panel (View â†’ Output â†’ Ã†therLight Extension) for welcome logs
- Check .vscode/settings.json for hasSeenWelcome flag value
- Verify voice panel webview initialized before welcome attempt
- Test with BUG-001 fixed (TOML parsing) to rule out crash blocking welcome
"""

reasoning_chain = [
    "1. User opens brand new workspace (no prior Ã†therLight)",
    "2. Extension activates, initializes resources",
    "3. Extension sets hasSeenWelcome = false (default for new workspace)",
    "4. User opens Voice Panel for first time",
    "5. Voice Panel webview initializes (takes 1-2 seconds)",
    "6. Extension waits 3 seconds, calls postWelcomeMessage()",
    "7. FAILURE: Welcome message not appearing in text area",
    "8. Possible: postWelcomeMessage() not called, or message lost, or timing wrong"
]

pattern_context = "Pattern-UX-001: Real-time feedback improves user experience"

success_impact = """
After BUG-003 complete:
âœ… Welcome message appears on fresh workspace install
âœ… Users see getting started guide
âœ… Users understand how to use Ã†therLight
âœ… Improved first-time user experience
âœ… Reduced support questions about "how to start"
"""

test_requirements = """
TDD Requirements (UI Task - 70% coverage):

RED Phase - Write tests FIRST:
1. Fresh workspace (hasSeenWelcome = false) â†’ Welcome message appears
2. Existing workspace (hasSeenWelcome = true) â†’ No welcome message
3. Welcome message contains expected content
4. hasSeenWelcome flag set to true after showing welcome
5. Timing: Welcome appears after webview ready (not before)

GREEN Phase - Implement fix:
1. Debug postWelcomeMessage() function
2. Fix timing issues (wait for webview ready)
3. Verify hasSeenWelcome flag logic
4. Test on fresh workspace multiple times

REFACTOR Phase - Improve timing reliability, add logging
"""

test_files = [
    "vscode-lumina/test/commands/voicePanel.test.ts",
    "vscode-lumina/test/features/welcomeMessage.test.ts"
]

test_coverage_requirement = 0.7

validation_criteria = [
    "Fresh workspace: Welcome message appears in text area",
    "Welcome message contains: '# ðŸš€ Welcome to Ã†therLight'",
    "hasSeenWelcome flag set to true after display",
    "Existing workspace: No welcome message (hasSeenWelcome = true)",
    "Timing: Welcome appears after webview fully loaded",
    "No race conditions or timing issues"
]

estimated_lines = 50
estimated_time = "1-2 hours"

files_to_modify = [
    "vscode-lumina/src/commands/voicePanel.ts (postWelcomeMessage function)",
    "vscode-lumina/src/extension.ts (welcome message timing logic)"
]

deliverables = [
    "Fix welcome message timing or initialization",
    "Ensure hasSeenWelcome defaults to false correctly",
    "Add logging for welcome message debugging",
    "Test on fresh workspace to verify welcome appears",
    "Verify BUG-001 fix doesn't block welcome (TOML parsing)"
]

error_handling = """
- Wrap postWelcomeMessage() in try-catch
- Handle webview not ready (timing issue)
- Handle settings read errors (hasSeenWelcome flag)
- Log welcome message flow for debugging
- Gracefully handle welcome message failures (don't crash)
- Retry welcome message if initial attempt fails (with max retries)
"""

performance_target = "Welcome message appears within 5 seconds of opening Voice Panel"
patterns = ["Pattern-UX-001", "Pattern-CODE-001"]
dependencies = ["BUG-001"]

[tasks.BUG-004]
id = "BUG-004"
name = "Investigate and resolve console warnings"
status = "completed"
phase = "ux-bugfix"
agent = "general-purpose"

why = """
Issue 2 from Sprint 18.2 testing: Platform-specific console warnings on extension launch.
User expectation: Clean extension activation, no scary warnings in console.
Current state: Multiple warnings on launch, looks unprofessional.
Impact: Non-blocking but affects user confidence, creates support questions.
"""

context = """
Console warnings observed during testing:
- VS Code/Cursor platform warnings (not Ã†therLight-specific)
- Some warnings benign, some may indicate actual issues
- Need to differentiate: Ã†therLight bugs vs platform quirks

Investigation needed:
1. Capture full console output from fresh launch
2. Identify which warnings from Ã†therLight vs VS Code/Cursor
3. Determine if warnings indicate problems or are cosmetic
4. Suppress benign warnings, fix actual issues
5. Document expected platform warnings in troubleshooting guide
"""

reasoning_chain = [
    "1. User launches Extension Development Host (F5)",
    "2. Extension activates, initializes services",
    "3. Console shows various warnings",
    "4. User sees warnings, becomes concerned",
    "5. Investigation: Which warnings are actionable?",
    "6. Fix actual issues, suppress cosmetic warnings",
    "7. Document expected platform warnings"
]

pattern_context = "Pattern-CODE-001: Code workflow, Pattern-IMPROVEMENT-001: Gap detection"

success_impact = """
After BUG-004 complete:
âœ… Identify and fix actual issues causing warnings
âœ… Suppress benign/cosmetic warnings
âœ… Clean console output on activation
âœ… Improved user confidence
âœ… Reduced support questions about warnings
"""

test_requirements = """
Testing Requirements (Investigation task):

1. Capture console output:
   - Fresh workspace launch
   - Existing workspace launch
   - Different platforms (Windows, Mac, Linux if available)

2. Categorize warnings:
   - Ã†therLight-caused warnings (our code)
   - VS Code platform warnings (not our fault)
   - Benign warnings (safe to ignore/suppress)
   - Critical warnings (need fixing)

3. Fix or document:
   - Fix Ã†therLight-caused warnings
   - Suppress benign warnings where possible
   - Document expected platform warnings
"""

validation_criteria = [
    "Console output captured and analyzed",
    "All Ã†therLight-caused warnings fixed or documented",
    "Benign warnings suppressed where possible",
    "Expected platform warnings documented in troubleshooting guide",
    "No critical warnings on extension activation"
]

estimated_lines = 50
estimated_time = "1-2 hours"

files_to_modify = [
    "vscode-lumina/src/extension.ts (activation logging)",
    "docs/TROUBLESHOOTING.md (expected warnings documentation)"
]

deliverables = [
    "Console output analysis report",
    "Fix actual issues causing warnings",
    "Suppress cosmetic warnings",
    "Document expected platform warnings",
    "Update troubleshooting guide"
]

error_handling = """
- Identify warnings that indicate actual problems
- Fix root causes of problematic warnings
- Add error boundaries to prevent future warnings
- Log only actionable issues (reduce noise)
"""

performance_target = "Investigation complete within 2 hours"
patterns = ["Pattern-CODE-001", "Pattern-IMPROVEMENT-001"]
dependencies = []

[tasks.BUILD-001]
id = "BUILD-001"
name = "Build Mac desktop app binaries (.dmg for Intel and Apple Silicon)"
status = "pending"
phase = "build"
agent = "infrastructure-agent"

why = """
Current state: Only Windows desktop app binaries exist in releases (.exe and .msi).
User expectation: Mac users need desktop app for voice transcription functionality.
Gap: No .dmg or .app files have ever been built or published for macOS.
Impact: Mac users cannot use voice capture feature (requires desktop app + Tauri).
Without this: Mac users limited to VS Code extension only (no voice transcription).
With this: Full feature parity between Windows and Mac users.
"""

context = """
Desktop app location: products/lumina-desktop/
Tauri config: src-tauri/tauri.conf.json (line 33: "targets": "all")
Build outputs expected:
- target/release/bundle/dmg/Lumina_0.18.5_x64.dmg (Intel)
- target/release/bundle/dmg/Lumina_0.18.5_aarch64.dmg (Apple Silicon)

Requirements:
- Mac build environment (macOS with Xcode)
- Rust toolchain installed
- Tauri CLI installed
- Code signing certificates (optional but recommended)

Integration points:
- VS Code extension expects desktop app at standard paths
- Extension activates voice capture via IPC with desktop app
- Desktop app provides: Voice capture, Whisper transcription, global hotkeys

Historical context:
- Tauri 2.0 supports macOS (CoreAudio for voice)
- Mac-specific setup guide exists: vscode-lumina/MAC_SETUP.md
- Extension works on Mac, but voice features require desktop app
- Current releases: Only Windows binaries (v0.18.4, v0.18.2, v0.18.0, v0.17.12, v0.17.10)
"""

reasoning_chain = [
    "1. Set up Mac build environment (macOS machine or CI runner)",
    "2. Install dependencies: Rust, Node.js, Tauri CLI",
    "3. Clone repository, navigate to products/lumina-desktop/",
    "4. Run: npm install (install frontend dependencies)",
    "5. Run: npm run tauri build (build for macOS)",
    "6. Verify .dmg files created in target/release/bundle/dmg/",
    "7. Test installation on Intel Mac (if available)",
    "8. Test installation on Apple Silicon Mac (if available)",
    "9. Code sign binaries (optional, for distribution)",
    "10. Update release workflow to include Mac builds",
    "11. Publish .dmg files to GitHub releases"
]

pattern_context = "Pattern-PUBLISH-001: Automated release pipeline, Pattern-CODE-001: Code workflow"

success_impact = """
After BUILD-001 complete:
âœ… Mac desktop app binaries available (.dmg for Intel and Apple Silicon)
âœ… Mac users can install and use voice capture feature
âœ… Feature parity between Windows and Mac
âœ… Expanded user base (Mac developers)
âœ… Professional release artifacts (all major platforms)
âœ… Future releases automatically include Mac builds
"""

test_requirements = """
Build Validation (Infrastructure Task):

Build Phase:
1. Rust compilation succeeds on macOS
2. Tauri bundling creates .dmg files
3. .dmg files contain correct app structure
4. App binary is executable

Installation Testing:
1. .dmg mounts correctly on macOS
2. Drag-to-Applications works
3. App launches without errors
4. Extension detects desktop app (IPC connection)
5. Voice capture works (microphone access)
6. Transcription works (Whisper integration)

Platform Testing:
- Intel Mac (x64): App launches, voice works
- Apple Silicon Mac (aarch64): App launches, voice works (native or Rosetta)
"""

test_files = []

validation_criteria = [
    "Mac build environment set up (macOS + Rust + Tauri CLI)",
    ".dmg files created successfully",
    "Intel .dmg tested on Intel Mac (or Rosetta on Apple Silicon)",
    "Apple Silicon .dmg tested on Apple Silicon Mac",
    "Desktop app launches without errors",
    "Voice capture functional on Mac",
    "Extension detects desktop app via IPC",
    "Release workflow updated to include Mac builds"
]

estimated_lines = 0
estimated_time = "4-6 hours (includes setup, build, testing)"

files_to_modify = [
    ".github/workflows/publish.yml (add macOS build job if CI used)",
    "scripts/publish-release.js (add Mac build step if automated)",
    "PUBLISHING.md (document Mac build process)"
]

deliverables = [
    "Lumina_0.18.5_x64.dmg (Intel Mac binary)",
    "Lumina_0.18.5_aarch64.dmg (Apple Silicon binary)",
    "Installation tested on both Mac architectures",
    "Voice capture verified working on Mac",
    "Documentation updated with Mac build steps",
    "GitHub release includes Mac binaries"
]

error_handling = """
- Handle missing dependencies (Rust, Xcode, Tauri CLI)
- Handle build failures (Rust compilation, Tauri bundling)
- Handle code signing issues (optional, can skip for first release)
- Handle platform-specific issues (CoreAudio, permissions)
- Document build errors and solutions in KNOWN_ISSUES.md
- Provide fallback: Unsigned .dmg if code signing fails
"""

performance_target = "Build time < 10 minutes on Mac (release build)"
patterns = ["Pattern-PUBLISH-001", "Pattern-CODE-001"]
dependencies = []

# ==============================================================================
# TEMPLATE TASKS - Quality Assurance & Documentation
# Injected from SPRINT_TEMPLATE.toml v1.1.0
# ==============================================================================

# ------------------------------------------------------------------------------
# Documentation Tasks (5 tasks)
# ------------------------------------------------------------------------------

[tasks.DOC-001]
id = "DOC-001"
name = "Update CHANGELOG.md with sprint changes"
phase = "documentation"
status = "pending"
description = "Document all changes made during sprint in CHANGELOG.md following Keep a Changelog format. Include Fixed section for bug fixes."
estimated_lines = 50
estimated_time = "30 minutes"
dependencies = []
agent = "documentation-agent"
deliverables = [
  "CHANGELOG.md updated with v0.18.5 section",
  "All bug fixes documented in Fixed section",
  "Issue numbers referenced (#Issue 4, #Issue 8, etc.)",
  "Breaking changes clearly marked (if any)"
]
performance_target = "Complete within 30 minutes"
patterns = ["Pattern-DOCS-001"]
files_to_modify = ["CHANGELOG.md"]
validation_criteria = [
  "CHANGELOG.md has v0.18.5 section",
  "All 4 bug fixes documented",
  "Issue numbers from SPRINT_18.2_MANUAL_TEST_CHECKLIST.md referenced",
  "Follows Keep a Changelog format"
]

[tasks.DOC-002]
id = "DOC-002"
name = "Update README.md if user-facing changes"
phase = "documentation"
status = "pending"
description = "Update README.md to reflect bug fixes. Add troubleshooting section for desktop app connection, update agent/skills counts."
estimated_lines = 100
estimated_time = "45 minutes"
dependencies = []
agent = "documentation-agent"
deliverables = [
  "README.md updated with bug fix notes",
  "Troubleshooting section added for desktop app",
  "Agent count corrected (14 â†’ 13 agents)",
  "Skills count expectations clarified (14-16 depending on version)"
]
performance_target = "Complete within 45 minutes"
patterns = ["Pattern-DOCS-001"]
files_to_modify = ["README.md"]
validation_criteria = [
  "Bug fixes mentioned in README",
  "Troubleshooting section covers desktop app manual start",
  "Resource counts accurate",
  "Links to documentation valid"
]

[tasks.DOC-003]
id = "DOC-003"
name = "Extract reusable patterns to docs/patterns/"
phase = "documentation"
status = "pending"
description = "Identify reusable patterns from bug fixes. Consider: TOML placeholder escaping pattern, webview message passing debugging pattern."
estimated_lines = 200
estimated_time = "1-2 hours"
dependencies = []
agent = "documentation-agent"
deliverables = [
  "New patterns extracted if high reusability (score 8+/10)",
  "Existing patterns updated if modified",
  "docs/patterns/INDEX.md updated",
  "CLAUDE.md references new patterns"
]
performance_target = "Complete within 2 hours"
patterns = ["Pattern-DOCS-001", "Pattern-IMPROVEMENT-001"]
files_to_modify = ["docs/patterns/*.md", "docs/patterns/INDEX.md", ".claude/CLAUDE.md"]
validation_criteria = [
  "High reusability patterns extracted",
  "Pattern files follow standard format",
  "INDEX.md updated",
  "CLAUDE.md references accurate"
]

[tasks.DOC-004]
id = "DOC-004"
name = "Update CLAUDE.md if workflow changes"
phase = "documentation"
status = "pending"
description = "Update .claude/CLAUDE.md pre-flight checklist with TOML placeholder validation rule. Keep concise."
estimated_lines = 50
estimated_time = "30 minutes"
dependencies = ["DOC-003"]
agent = "documentation-agent"
deliverables = [
  "CLAUDE.md pre-flight checklist updated",
  "Add: 'Check for template literals in TOML strings'",
  "Pattern references added",
  "File size remains under 600 lines"
]
performance_target = "Complete within 30 minutes"
patterns = ["Pattern-DOCS-001"]
files_to_modify = [".claude/CLAUDE.md"]
validation_criteria = [
  "Pre-flight checklist includes TOML placeholder check",
  "CLAUDE.md under 600 lines",
  "Pattern references accurate"
]

[tasks.DOC-005]
id = "DOC-005"
name = "Refactor documentation for context optimization"
phase = "documentation"
status = "pending"
description = "CRITICAL: Refactor documentation to reduce bloat. Target: 10-20% context reduction while improving clarity. NOT additive."
estimated_lines = -500
estimated_time = "3-4 hours"
dependencies = ["DOC-003", "DOC-004"]
agent = "documentation-agent"
deliverables = [
  "Context reduction report (BEFORE/AFTER line counts)",
  "All docs refactored for AI consumption",
  "Verbose sections extracted to patterns",
  "Redundant content removed",
  "10-20% context reduction achieved"
]
performance_target = "Complete within 4 hours"
patterns = ["Pattern-DOCS-001"]
files_to_modify = [".claude/CLAUDE.md", "README.md", "internal/agents/*-agent-context.md"]
validation_criteria = [
  "BEFORE line counts documented",
  "AFTER line counts documented",
  "10-20% context reduction achieved",
  "No information lost (moved to patterns)",
  "AI can still find information (test queries)"
]

# ------------------------------------------------------------------------------
# Quality Assurance Tasks (4 tasks)
# ------------------------------------------------------------------------------

[tasks.QA-001]
id = "QA-001"
name = "Run ripple analysis for breaking changes"
phase = "quality-assurance"
status = "pending"
description = "Analyze code changes for ripple effects. Verify TOML format changes don't break existing sprint files."
estimated_lines = 0
estimated_time = "1 hour"
dependencies = []
agent = "testing-agent"
deliverables = [
  "Ripple analysis report",
  "Breaking changes documented (if any)",
  "All existing sprint files tested with fix",
  "Migration guide if breaking"
]
performance_target = "Complete within 1 hour"
patterns = ["Pattern-TDD-001", "Pattern-CODE-001"]
files_to_modify = ["CHANGELOG.md"]
validation_criteria = [
  "All breaking changes identified",
  "Affected systems documented",
  "Existing sprint files parse correctly",
  "Migration path provided if needed"
]

[tasks.QA-002]
id = "QA-002"
name = "Verify test coverage meets targets"
phase = "quality-assurance"
status = "pending"
description = "Run test coverage analysis. Verify meets targets: Infrastructure 90%, UI 70%."
estimated_lines = 200
estimated_time = "2-3 hours"
dependencies = []
agent = "testing-agent"
deliverables = [
  "Test coverage report generated",
  "Coverage meets targets",
  "New tests added for bug fixes",
  "Coverage report saved"
]
performance_target = "Complete within 3 hours"
patterns = ["Pattern-TDD-001"]
files_to_modify = ["vscode-lumina/test/**/*.test.ts"]
validation_criteria = [
  "Run: npm test -- --coverage",
  "Infrastructure coverage >= 90%",
  "UI coverage >= 70%",
  "Bug fixes have tests"
]

[tasks.QA-003]
id = "QA-003"
name = "Run dependency audit for vulnerabilities"
phase = "quality-assurance"
status = "pending"
description = "Run npm audit on all packages. Fix critical/high vulnerabilities."
estimated_lines = 0
estimated_time = "1 hour"
dependencies = []
agent = "infrastructure-agent"
deliverables = [
  "npm audit run on all packages",
  "Critical/high vulnerabilities fixed",
  "Audit report saved",
  "Medium/low documented with rationale"
]
performance_target = "Complete within 1 hour"
patterns = ["Pattern-PUBLISH-004"]
files_to_modify = ["package.json", "packages/*/package.json"]
validation_criteria = [
  "Run: npm audit --workspaces",
  "No critical or high vulnerabilities",
  "Medium/low documented",
  "All packages audited"
]

[tasks.QA-004]
id = "QA-004"
name = "Validate TypeScript compilation (zero errors)"
phase = "quality-assurance"
status = "pending"
description = "Run TypeScript compiler on all packages. Fix all errors."
estimated_lines = 100
estimated_time = "1-2 hours"
dependencies = []
agent = "infrastructure-agent"
deliverables = [
  "TypeScript compiles with zero errors",
  "No @ts-ignore suppressions",
  "Type definitions current",
  "All packages compile"
]
performance_target = "Complete within 2 hours"
patterns = ["Pattern-CODE-001"]
files_to_modify = ["vscode-lumina/src/**/*.ts", "packages/*/src/**/*.ts"]
validation_criteria = [
  "Run: npm run compile (vscode-lumina)",
  "Run: npm run build --workspaces",
  "Zero TypeScript errors",
  "All packages compile"
]

[tasks.QA-005]
id = "QA-005"
name = "Run protection audit on working code"
phase = "quality-assurance"
status = "pending"
description = "Run protection-audit skill to verify code protection system. Generate protection reports, verify consistency with CODE_PROTECTION_POLICY.md, identify unprotected passing features from Sprint 18.2 testing."
estimated_lines = 0
estimated_time = "1-2 hours"
dependencies = []
agent = "infrastructure-agent"
skill = "protection-audit"
why = """
Sprint 18.2 manual testing identified working features (PASS) and broken features (FAIL).
Current state: 12 files have protection annotations, but no audit has been run to verify consistency.
User expectation: Protection system verified, CODE_PROTECTION_POLICY.md matches code, unprotected passing features identified.
Without audit: Cannot verify protection coverage, may have inconsistencies between policy and code.
With audit: Clear visibility into what's protected, what needs protection, system health verified.
"""
context = """
Protection system implemented in PROTECT-001 and PROTECT-002:
- 12 files annotated with @protected/@maintainable
- CODE_PROTECTION_POLICY.md documents 5 core protected files
- Pre-commit hook enforces protection approval
- scripts/validate-protection.js validates protected file changes

Audit needs:
1. Scan codebase for all protection annotations
2. Generate summary report (counts by protection level)
3. Verify consistency with CODE_PROTECTION_POLICY.md
4. Show coverage metrics (X files protected out of Y total)
5. Identify passing features from Sprint 18.2 that lack protection

Integration points:
- scripts/audit-protection.js (to be created by skill)
- CODE_PROTECTION_POLICY.md (reference document)
- SPRINT_18.2_MANUAL_TEST_CHECKLIST.md (passing features reference)

Historical: Protection system built but never audited - need baseline metrics.
"""
reasoning_chain = [
    "1. User completes Sprint 18.2 manual testing",
    "2. Some features PASS, some FAIL (documented in checklist)",
    "3. User wants to protect passing features to prevent regression",
    "4. Protection-audit skill creates audit script",
    "5. Script scans codebase for protection annotations",
    "6. Script generates summary report showing coverage",
    "7. Script verifies CODE_PROTECTION_POLICY.md consistency",
    "8. Script identifies unprotected passing features",
    "9. User reviews report, decides which features need protection",
    "10. User runs protect skill to annotate critical passing features"
]
pattern_context = "Pattern-IMPROVEMENT-001: Gap detection, Pattern-CODE-001: Code workflow"
success_impact = """
After QA-005 complete:
âœ… Protection audit script created (scripts/audit-protection.js)
âœ… Summary report generated (protection counts, coverage metrics)
âœ… Consistency verified with CODE_PROTECTION_POLICY.md
âœ… Unprotected passing features identified
âœ… Baseline protection metrics established
âœ… User visibility into protection system health
âœ… Foundation for future protection maintenance
"""
deliverables = [
  "scripts/audit-protection.js created",
  "Protection summary report generated",
  "Consistency check completed (CODE_PROTECTION_POLICY.md vs code)",
  "Unprotected passing features identified (from Sprint 18.2)",
  "Coverage metrics documented (X% of files protected)",
  "Baseline audit report saved for future comparison"
]
performance_target = "Audit execution < 5 seconds"
patterns = ["Pattern-IMPROVEMENT-001", "Pattern-CODE-001"]
files_to_create = [
    "scripts/audit-protection.js"
]
validation_criteria = [
  "scripts/audit-protection.js exists and is executable",
  "Run: node scripts/audit-protection.js (summary report generated)",
  "Run: node scripts/audit-protection.js --verify (consistency check)",
  "Run: node scripts/audit-protection.js --coverage (metrics shown)",
  "Unprotected passing features documented",
  "Audit completes in < 5 seconds"
]

# ------------------------------------------------------------------------------
# Agent Synchronization Tasks (2 tasks)
# ------------------------------------------------------------------------------

[tasks.AGENT-001]
id = "AGENT-001"
name = "Update agent context files with learnings"
phase = "agent-sync"
status = "pending"
description = "Update agent context files with bug fix learnings. Add pitfalls for TOML placeholders, webview message passing."
estimated_lines = 100
estimated_time = "1 hour"
dependencies = ["DOC-003"]
agent = "documentation-agent"
deliverables = [
  "Agent context files updated",
  "New pitfalls added (TOML placeholders, webview messages)",
  "Example task executions updated",
  "Pattern references added"
]
performance_target = "Complete within 1 hour"
patterns = ["Pattern-IMPROVEMENT-001"]
files_to_modify = ["internal/agents/*-agent-context.md"]
validation_criteria = [
  "Agent contexts current",
  "New pitfalls documented",
  "Examples reflect best practices",
  "Pattern references accurate"
]

[tasks.AGENT-002]
id = "AGENT-002"
name = "Update KNOWN_ISSUES.md with pitfalls"
phase = "agent-sync"
status = "pending"
description = "Document bugs from Sprint 18.2 testing in KNOWN_ISSUES.md with prevention strategies."
estimated_lines = 50
estimated_time = "30 minutes"
dependencies = []
agent = "documentation-agent"
deliverables = [
  "KNOWN_ISSUES.md updated",
  "Issue 4 and Issue 8 documented",
  "Prevention strategies included",
  "Time-wasted estimates added"
]
performance_target = "Complete within 30 minutes"
patterns = ["Pattern-IMPROVEMENT-001"]
files_to_modify = ["docs/KNOWN_ISSUES.md"]
validation_criteria = [
  "New issues documented",
  "Prevention strategies clear",
  "Issues categorized",
  "Time estimates included"
]

# ------------------------------------------------------------------------------
# Infrastructure Validation Tasks (2 tasks)
# ------------------------------------------------------------------------------

[tasks.INFRA-001]
id = "INFRA-001"
name = "Verify git hooks functioning"
phase = "infrastructure"
status = "pending"
description = "Test pre-commit hooks. Verify sprint schema validation blocks invalid TOML."
estimated_lines = 0
estimated_time = "30 minutes"
dependencies = []
agent = "infrastructure-agent"
deliverables = [
  "Pre-commit hooks tested",
  "Invalid TOML commits blocked",
  "Hook scripts current",
  "Documentation updated"
]
performance_target = "Complete within 30 minutes"
patterns = ["Pattern-GIT-001"]
files_to_modify = [".git/hooks/pre-commit", "scripts/validate-sprint-schema.js"]
validation_criteria = [
  "Test: Invalid TOML â†’ Commit blocked",
  "All hooks installed and executable",
  "Hook documentation current"
]

[tasks.INFRA-002]
id = "INFRA-002"
name = "Run sprint schema validation script"
phase = "infrastructure"
status = "pending"
description = "Run scripts/validate-sprint-schema.js on all sprint files. Fix validation errors."
estimated_lines = 0
estimated_time = "15 minutes"
dependencies = []
agent = "infrastructure-agent"
deliverables = [
  "Validation script run successfully",
  "All validation errors fixed",
  "All sprint files validate",
  "Validation report clean"
]
performance_target = "Complete within 15 minutes"
patterns = ["Pattern-SPRINT-PLAN-001"]
files_to_modify = ["internal/sprints/*.toml"]
validation_criteria = [
  "Run: node scripts/validate-sprint-schema.js",
  "Zero validation errors",
  "All required fields present",
  "No circular dependencies"
]

# ------------------------------------------------------------------------------
# Configuration Validation Tasks (1 task)
# ------------------------------------------------------------------------------

[tasks.CONFIG-001]
id = "CONFIG-001"
name = "Validate settings schema if changed"
phase = "infrastructure"
status = "pending"
description = "Verify settings schema if changed. Test settings UI in VS Code."
estimated_lines = 50
estimated_time = "30 minutes"
dependencies = []
agent = "infrastructure-agent"
deliverables = [
  "Settings schema validated",
  "Settings UI tested",
  "Default values appropriate",
  "Settings documentation current"
]
performance_target = "Complete within 30 minutes"
patterns = ["Pattern-CODE-001"]
files_to_modify = ["vscode-lumina/package.json"]
validation_criteria = [
  "Settings schema valid JSON",
  "Settings appear in VS Code preferences",
  "Default values work",
  "Descriptions clear"
]

# ------------------------------------------------------------------------------
# Suggested Tasks (4 tasks - can skip with justification)
# ------------------------------------------------------------------------------

[tasks.PERF-001]
id = "PERF-001"
name = "Run performance regression tests"
phase = "performance"
status = "pending"
description = "Run performance benchmarks. Flag regressions >10%."
estimated_lines = 100
estimated_time = "1-2 hours"
dependencies = []
agent = "testing-agent"
deliverables = [
  "Performance benchmarks run",
  "Comparison to baseline",
  "Regressions identified",
  "Performance report saved"
]
performance_target = "Complete within 2 hours"
patterns = ["Pattern-TDD-001"]
validation_criteria = [
  "Run: npm run test:performance",
  "No regressions >10%",
  "Report generated",
  "Baseline updated if improvements"
]

[tasks.SEC-001]
id = "SEC-001"
name = "Security vulnerability scan"
phase = "security"
status = "pending"
description = "Run security scanning beyond npm audit. Check for code vulnerabilities."
estimated_lines = 0
estimated_time = "1 hour"
dependencies = ["QA-003"]
agent = "infrastructure-agent"
deliverables = [
  "Security scan completed",
  "Vulnerabilities documented",
  "Critical issues fixed",
  "Security report saved"
]
performance_target = "Complete within 1 hour"
patterns = ["Pattern-PUBLISH-004"]
validation_criteria = [
  "Security tools run",
  "No critical vulnerabilities",
  "Report generated"
]

[tasks.COMPAT-001]
id = "COMPAT-001"
name = "Cross-platform testing (Windows/Mac/Linux)"
phase = "compatibility"
status = "pending"
description = "Test extension on Windows, macOS, Linux. Verify bug fixes work on all platforms."
estimated_lines = 0
estimated_time = "2 hours"
dependencies = []
agent = "testing-agent"
deliverables = [
  "Extension tested on all platforms",
  "Platform-specific issues documented",
  "All features work on all platforms"
]
performance_target = "Complete within 2 hours"
patterns = ["Pattern-TDD-001"]
validation_criteria = [
  "Test on Windows",
  "Test on macOS",
  "Test on Linux",
  "All features work"
]

[tasks.COMPAT-002]
id = "COMPAT-002"
name = "Backwards compatibility check"
phase = "compatibility"
status = "pending"
description = "Verify extension works with older VS Code versions. Test TOML format changes don't break old sprints."
estimated_lines = 50
estimated_time = "1 hour"
dependencies = []
agent = "testing-agent"
deliverables = [
  "Extension tested on minimum VS Code version",
  "Old sprint files tested with fixes",
  "Backwards incompatibilities documented",
  "Migration guide if breaking"
]
performance_target = "Complete within 1 hour"
patterns = ["Pattern-PUBLISH-004"]
validation_criteria = [
  "Extension activates on minimum version",
  "Old sprint files parse correctly",
  "No undocumented breaking changes"
]

# ------------------------------------------------------------------------------
# Conditional Tasks - Publishing (5 tasks - Sprint includes v0.18.5 release)
# ------------------------------------------------------------------------------

[tasks.PUB-001]
id = "PUB-001"
name = "Run pre-publish validation checklist"
phase = "publishing"
status = "pending"
description = "Run Pattern-PUBLISH-004 pre-publish validation. Verify all packages ready for v0.18.5 release."
estimated_lines = 0
estimated_time = "30 minutes"
dependencies = []
agent = "infrastructure-agent"
skill = "publish"
condition = "sprint_includes_publishing_v0.18.5"
deliverables = [
  "Pre-publish checklist completed",
  "All validations passing",
  "Version numbers synchronized to 0.18.5",
  "Packages built successfully"
]
performance_target = "Complete within 30 minutes"
patterns = ["Pattern-PUBLISH-004", "Pattern-PUBLISH-001"]
validation_criteria = [
  "All package versions = 0.18.5",
  "CHANGELOG.md updated",
  "All tests passing",
  "TypeScript compiles (zero errors)",
  "No runtime npm dependencies"
]

[tasks.PUB-002]
id = "PUB-002"
name = "Build and verify .vsix package"
phase = "publishing"
status = "pending"
description = "Build .vsix extension package. Test installation and activation locally."
estimated_lines = 0
estimated_time = "30 minutes"
dependencies = ["PUB-001"]
agent = "infrastructure-agent"
skill = "publish"
condition = "sprint_includes_publishing_v0.18.5"
deliverables = [
  ".vsix package built successfully",
  "Package installed locally",
  "Extension activates without errors",
  "Bug fixes verified in packaged extension"
]
performance_target = "Complete within 30 minutes"
patterns = ["Pattern-PUBLISH-001"]
validation_criteria = [
  "Run: vsce package",
  ".vsix file created",
  "Install: code --install-extension",
  "Extension activates (<200ms)",
  "Bug fixes working in package"
]

[tasks.PUB-003]
id = "PUB-003"
name = "Verify no runtime npm dependencies"
phase = "publishing"
status = "pending"
description = "Verify extension has zero runtime npm dependencies (Pattern-PUBLISH-003)."
estimated_lines = 0
estimated_time = "15 minutes"
dependencies = []
agent = "infrastructure-agent"
skill = "publish"
condition = "sprint_includes_publishing_v0.18.5"
deliverables = [
  "package.json dependencies audited",
  "Only whitelisted runtime dependencies",
  "Node.js built-ins used",
  "Dependency audit clean"
]
performance_target = "Complete within 15 minutes"
patterns = ["Pattern-PUBLISH-003"]
validation_criteria = [
  "Only whitelisted packages (aetherlight-*, @iarna/toml, form-data, node-fetch, ws)",
  "No runtime packages like glob, lodash, moment",
  "DevDependencies OK"
]

[tasks.PUB-004]
id = "PUB-004"
name = "Generate release artifacts"
phase = "publishing"
status = "pending"
description = "Generate release artifacts: .vsix, CHANGELOG excerpt, GitHub release notes for v0.18.5."
estimated_lines = 0
estimated_time = "30 minutes"
dependencies = ["PUB-002", "DOC-001"]
agent = "documentation-agent"
condition = "sprint_includes_publishing_v0.18.5"
deliverables = [
  ".vsix package ready",
  "CHANGELOG excerpt for release notes",
  "GitHub release notes drafted",
  "Release artifacts validated"
]
performance_target = "Complete within 30 minutes"
patterns = ["Pattern-PUBLISH-001"]
validation_criteria = [
  ".vsix file exists and tested",
  "CHANGELOG.md has v0.18.5 section",
  "Release notes drafted",
  "All artifacts ready"
]

[tasks.PUB-005]
id = "PUB-005"
name = "Post-publish verification"
phase = "publishing"
status = "pending"
description = "After publishing v0.18.5, verify extension in marketplace. Test clean installation."
estimated_lines = 0
estimated_time = "30 minutes"
dependencies = ["PUB-004"]
agent = "infrastructure-agent"
skill = "publish"
condition = "sprint_includes_publishing_v0.18.5"
deliverables = [
  "Extension visible in marketplace",
  "Clean installation tested",
  "Extension activates",
  "npm packages published"
]
performance_target = "Complete within 30 minutes"
patterns = ["Pattern-PUBLISH-001"]
validation_criteria = [
  "Search marketplace: 'aetherlight'",
  "Version 0.18.5 appears",
  "Fresh install from marketplace",
  "Extension activates (<200ms)",
  "Bug fixes working"
]

# ------------------------------------------------------------------------------
# Conditional Tasks - User Experience (3 tasks - Sprint has UX/UI changes)
# ------------------------------------------------------------------------------

[tasks.UX-001]
id = "UX-001"
name = "Create upgrade documentation"
phase = "user-experience"
status = "pending"
description = "Create upgrade guide for users migrating to v0.18.5 with bug fixes."
estimated_lines = 200
estimated_time = "1-2 hours"
dependencies = ["DOC-001", "QA-001"]
agent = "documentation-agent"
condition = "sprint_has_user_facing_changes"
deliverables = [
  "Upgrade guide created",
  "Bug fixes documented with examples",
  "TOML format changes explained (if applicable)",
  "Troubleshooting tips included"
]
performance_target = "Complete within 2 hours"
patterns = ["Pattern-DOCS-001"]
files_to_modify = ["docs/UPGRADE.md"]
validation_criteria = [
  "Bug fixes documented",
  "Migration steps clear",
  "Examples provided",
  "Linked from CHANGELOG"
]

[tasks.UX-002]
id = "UX-002"
name = "Update screenshots and demos"
phase = "user-experience"
status = "pending"
description = "Update screenshots if UI changed. Show Sprint Panel working, task template loading working."
estimated_lines = 0
estimated_time = "1-2 hours"
dependencies = ["DOC-002"]
agent = "documentation-agent"
condition = "sprint_has_ui_changes"
deliverables = [
  "Screenshots updated in README",
  "Sprint Panel screenshots current",
  "Marketplace images updated",
  "Visual documentation accurate"
]
performance_target = "Complete within 2 hours"
patterns = ["Pattern-DOCS-001"]
files_to_modify = ["README.md", "docs/images/"]
validation_criteria = [
  "Screenshots show current UI",
  "Sprint Panel functionality visible",
  "Image quality high",
  "Marketplace images updated"
]

[tasks.UX-003]
id = "UX-003"
name = "Generate user-facing release notes"
phase = "user-experience"
status = "pending"
description = "Generate user-friendly release notes for v0.18.5. Focus on benefits: 'Sprint Panel now works', 'Task templates load correctly'."
estimated_lines = 100
estimated_time = "1 hour"
dependencies = ["DOC-001"]
agent = "documentation-agent"
condition = "sprint_has_user_facing_changes"
deliverables = [
  "User-facing release notes drafted",
  "Benefits highlighted",
  "Examples provided",
  "Release notes reviewed"
]
performance_target = "Complete within 1 hour"
patterns = ["Pattern-DOCS-001"]
files_to_modify = ["CHANGELOG.md", "docs/RELEASE_NOTES.md"]
validation_criteria = [
  "Release notes focus on user benefits",
  "Examples for bug fixes",
  "Language accessible",
  "Clear value proposition"
]

# ------------------------------------------------------------------------------
# Retrospective Tasks (2 tasks - EVERY sprint)
# ------------------------------------------------------------------------------

[tasks.RETRO-001]
id = "RETRO-001"
name = "Sprint retrospective"
phase = "retrospective"
status = "pending"
description = "Conduct sprint retrospective. Document what went well, what didn't, improvements for next sprint."
estimated_lines = 100
estimated_time = "1 hour"
dependencies = []
agent = "documentation-agent"
deliverables = [
  "Sprint retrospective document created",
  "What went well documented",
  "What didn't go well documented",
  "Improvements for next sprint",
  "Action items created"
]
performance_target = "Complete within 1 hour"
patterns = ["Pattern-IMPROVEMENT-001"]
files_to_modify = ["internal/sprints/retrospectives/SPRINT-18.2.2-retrospective.md"]
validation_criteria = [
  "Retrospective document created",
  "All sections completed",
  "Action items clear",
  "Learnings captured"
]

[tasks.RETRO-002]
id = "RETRO-002"
name = "Extract patterns from sprint learnings"
phase = "retrospective"
status = "pending"
description = "Review retrospective and extract high-value patterns (score 7+/10). Consider: TOML validation pattern, webview debugging pattern."
estimated_lines = 200
estimated_time = "1-2 hours"
dependencies = ["RETRO-001"]
agent = "documentation-agent"
deliverables = [
  "High-value patterns extracted",
  "Pattern-*.md files created",
  "INDEX.md updated",
  "CLAUDE.md references patterns"
]
performance_target = "Complete within 2 hours"
patterns = ["Pattern-DOCS-001", "Pattern-IMPROVEMENT-001"]
files_to_modify = ["docs/patterns/*.md", "docs/patterns/INDEX.md", ".claude/CLAUDE.md"]
validation_criteria = [
  "Patterns assessed for reusability",
  "High-value patterns (7+/10) extracted",
  "Pattern files follow format",
  "INDEX.md updated"
]

# ------------------------------------------------------------------------------
# Research Tasks (3 tasks - JEPA Pattern Prediction)
# ------------------------------------------------------------------------------

[tasks.JEPA-001]
id = "JEPA-001"
name = "Run JEPA PoC - Validate pattern prediction hypothesis"
status = "pending"
phase = "research"
agent = "infrastructure-agent"

why = """
User hypothesis: JEPA (Joint Embedding Predictive Architecture) is "TDD for embeddings" - it predicts abstract representations before generating outputs.
Current state: Pattern selection is reactive (during coding), not predictive (before coding).
Opportunity: Apply JEPA principles to predict which patterns will be needed before writing code.
Research question: Can we predict patterns from task descriptions with >60% accuracy?
Without this: Continue reactive pattern selection, miss self-improvement opportunities.
With this: Proactive pattern recommendation, automated gap detection, self-improving system.
"""

context = """
JEPA Background (Meta/Yann LeCun, Sep 2025):
- Predicts abstract representations in embedding space (not pixel/token space)
- LLM-JEPA learns approximately linear transformations: Enc(Code) â‰ˆ W Ã— Enc(Text)
- Outperforms standard LLM training by significant margin
- Paper: ArXiv 2509.14252

Ã†therLight Application:
- We have 77+ patterns in docs/patterns/
- We have 12+ sprints with 200+ tasks (training data)
- Pattern references in task descriptions (implicit labels)
- Hypothesis: Taskâ†’Patterns might be approximately linear (like Textâ†’Code in LLM-JEPA)

PoC Scope:
- Encode 10 most-used patterns (subset)
- Test with 5 recent tasks (validation set)
- Measure: Accuracy@3 (are correct patterns in top 3 predictions?)
- Baseline: k-NN similarity search (no training required)

Success Criteria: Accuracy@3 > 60%
"""

reasoning_chain = [
    "1. Select 10 most-used patterns from pattern library",
    "2. Generate embeddings for each pattern using LLM (Sonnet 4.5)",
    "3. Select 5 recent tasks with known pattern usage",
    "4. Generate task embeddings from task descriptions",
    "5. For each task: Find k-nearest pattern embeddings (k=3)",
    "6. Compare predicted patterns to actual patterns used",
    "7. Calculate Accuracy@3: (correct predictions / total tasks)",
    "8. If accuracy >60%: PoC succeeds, proceed to Phase 2",
    "9. If accuracy <60%: Analyze failures, adjust approach"
]

pattern_context = "Pattern-IMPROVEMENT-001: Gap detection, Pattern-TDD-001: Predict-first methodology"

success_impact = """
After JEPA-001 complete:
âœ… Hypothesis validated (or invalidated) with empirical data
âœ… Understand feasibility of pattern prediction
âœ… Baseline accuracy established (k-NN similarity)
âœ… Decision point: Proceed to full implementation or adjust approach
âœ… Research document updated with findings
"""

test_requirements = """
PoC Validation (Research task - No formal tests, but validation required):

Validation Steps:
1. Pattern Selection: 10 most-used patterns identified
2. Task Selection: 5 recent tasks with clear pattern usage
3. Embedding Quality: Verify patterns cluster meaningfully (visual check)
4. Prediction Accuracy: Measure Accuracy@3
5. Analysis: Understand what works, what doesn't
6. Documentation: Record findings in research document
"""

validation_criteria = [
    "10 patterns selected and encoded",
    "5 tasks selected with known pattern usage",
    "k-NN similarity search implemented",
    "Accuracy@3 measured and documented",
    "Findings recorded: what worked, what didn't",
    "Decision made: proceed to Phase 2 or adjust approach",
    "Research document updated with results"
]

estimated_lines = 200
estimated_time = "4-6 hours"

files_to_create = [
    "services/PatternEmbedder.ts (PoC version)",
    "services/TaskEmbedder.ts (PoC version)",
    "scripts/jepa_poc.ts (PoC script)"
]

files_to_modify = [
    "internal/research/JEPA_PATTERN_PREDICTION_RESEARCH.md (add results section)"
]

deliverables = [
    "10 pattern embeddings generated",
    "5 task embeddings generated",
    "k-NN similarity search working",
    "Accuracy@3 measurement: X%",
    "Findings documented in research doc",
    "Go/No-Go decision for Phase 2"
]

error_handling = """
- Handle embedding generation failures gracefully
- Validate embedding dimensions match
- Handle edge cases: No similar patterns found
- Log all intermediate results for debugging
- Clear error messages if PoC fails
"""

performance_target = "PoC execution < 5 minutes (embedding generation + prediction)"
patterns = ["Pattern-IMPROVEMENT-001", "Pattern-TDD-001"]
dependencies = []

[tasks.JEPA-002]
id = "JEPA-002"
name = "Build embedding infrastructure (if PoC succeeds)"
status = "pending"
phase = "research"
agent = "infrastructure-agent"

why = """
CONDITIONAL on JEPA-001 success (Accuracy@3 >60%).
Current state: PoC validated hypothesis, but limited to 10 patterns.
Gap: Need production-ready infrastructure for all 77+ patterns.
Solution: Build scalable embedding infrastructure.
Without this: Can't use JEPA in production, stuck with reactive patterns.
With this: Foundation for proactive pattern prediction in sprint planning.
"""

context = """
Requirements:
1. Pattern Embedding Database: All 77+ patterns encoded
2. Task Embedding Service: Real-time task encoding
3. Similarity Search: Fast retrieval (cosine similarity)
4. Caching: Pre-computed pattern embeddings
5. API: Integration points for sprint-plan skill

Architecture:
- PatternEmbedder service: Encodes patterns, caches embeddings
- TaskEmbedder service: Encodes tasks on-demand
- EmbeddingMatcher service: Similarity search + ranking
- Storage: pattern_embeddings.json (77+ pattern vectors)

Integration: Sprint-plan skill calls EmbeddingMatcher for pattern recommendations
"""

reasoning_chain = [
    "1. Expand PoC code to handle all 77+ patterns",
    "2. Create production-ready services (error handling, logging)",
    "3. Generate embeddings for all patterns (one-time batch)",
    "4. Implement caching layer (avoid re-encoding)",
    "5. Build similarity search API",
    "6. Test with multiple tasks (validation)",
    "7. Integrate with sprint-plan skill (optional for this sprint)",
    "8. Document API and usage"
]

success_impact = """
After JEPA-002 complete:
âœ… Production-ready embedding infrastructure
âœ… All 77+ patterns encoded and cached
âœ… Fast similarity search (<100ms per query)
âœ… Foundation for sprint integration (Phase 3)
âœ… Reusable for future ML features
"""

test_requirements = """
TDD Requirements (Infrastructure Task - 90% coverage):

RED Phase:
1. PatternEmbedder.embedPattern(patternId) returns embedding
2. EmbeddingMatcher.findSimilar(taskEmb, topK) returns ranked patterns
3. Caching: Second call faster than first (cache hit)
4. All 77 patterns encoded successfully
5. Similarity search returns valid results

GREEN Phase: Implement services
REFACTOR Phase: Optimize performance, add caching
"""

test_files = [
    "vscode-lumina/test/services/PatternEmbedder.test.ts",
    "vscode-lumina/test/services/EmbeddingMatcher.test.ts"
]

test_coverage_requirement = 0.9

validation_criteria = [
    "All 77+ patterns encoded",
    "Embeddings cached (pattern_embeddings.json exists)",
    "Similarity search works (<100ms per query)",
    "API documented with examples",
    "Tests pass with 90% coverage",
    "Integration points identified for sprint-plan"
]

estimated_lines = 300
estimated_time = "1-2 days"

files_to_create = [
    "vscode-lumina/src/services/PatternEmbedder.ts",
    "vscode-lumina/src/services/TaskEmbedder.ts",
    "vscode-lumina/src/services/EmbeddingMatcher.ts",
    "vscode-lumina/data/pattern_embeddings.json"
]

deliverables = [
    "PatternEmbedder service (production)",
    "TaskEmbedder service (production)",
    "EmbeddingMatcher service (similarity search)",
    "pattern_embeddings.json (77+ embeddings)",
    "Unit tests (90% coverage)",
    "API documentation"
]

error_handling = """
- Wrap embedding generation in try-catch
- Handle missing patterns gracefully
- Handle embedding dimension mismatches
- Validate embeddings before caching
- Provide fallback: keyword matching if embeddings fail
- Log all errors with context
"""

performance_target = "Pattern embedding: <200ms, Task embedding: <100ms, Similarity search: <50ms"
patterns = ["Pattern-CODE-001", "Pattern-TDD-001"]
dependencies = ["JEPA-001"]

[tasks.JEPA-003]
id = "JEPA-003"
name = "Document findings and create implementation sprint"
status = "pending"
phase = "research"
agent = "documentation-agent"

why = """
ALWAYS required (regardless of PoC success/failure).
Current state: Research complete, findings exist but not formally documented.
Gap: Learnings not captured for future reference.
Solution: Document findings, update research doc, create next sprint if needed.
Without this: Lose research insights, can't build on this work.
With this: Clear record of what was learned, next steps defined.
"""

context = """
Documentation Tasks:
1. Update JEPA_PATTERN_PREDICTION_RESEARCH.md with results
2. Add "Results" section with PoC findings
3. Document accuracy metrics (Accuracy@3, what worked, what didn't)
4. Record lessons learned
5. If PoC succeeded: Create implementation sprint for Phase 3 (integration)
6. If PoC failed: Document why, recommend adjustments or alternative approaches

Integration: Results feed into Pattern-IMPROVEMENT-001 (gap detection)
"""

reasoning_chain = [
    "1. Read JEPA-001 results (accuracy, findings)",
    "2. Update research document with Results section",
    "3. Document accuracy metrics and analysis",
    "4. Record lessons learned (what worked, what didn't)",
    "5. Decision: If PoC succeeded (>60%), create Phase 3 sprint",
    "6. Decision: If PoC failed (<60%), recommend adjustments",
    "7. Update Pattern-IMPROVEMENT-001 if new patterns identified",
    "8. Share findings with team"
]

success_impact = """
After JEPA-003 complete:
âœ… Research findings formally documented
âœ… Learnings captured for future work
âœ… Next steps clearly defined
âœ… Implementation sprint created (if applicable)
âœ… Team understands JEPA feasibility for Ã†therLight
"""

validation_criteria = [
    "Research document updated with Results section",
    "Accuracy metrics documented",
    "Lessons learned recorded",
    "Next steps clearly defined",
    "Implementation sprint created (if PoC succeeded)",
    "Findings shared with team"
]

estimated_lines = 200
estimated_time = "1-2 hours"

files_to_modify = [
    "internal/research/JEPA_PATTERN_PREDICTION_RESEARCH.md (add Results section)"
]

files_to_create = [
    "internal/sprints/ACTIVE_SPRINT_JEPA_IMPLEMENTATION.toml (if PoC succeeds)"
]

deliverables = [
    "Research document updated with findings",
    "Accuracy metrics documented",
    "Lessons learned captured",
    "Next steps defined",
    "Implementation sprint created (if applicable)"
]

error_handling = """
- Handle case where PoC didn't run (document why)
- Handle inconclusive results (partial success)
- Document both successes and failures
- Clear recommendations regardless of outcome
"""

performance_target = "Complete within 2 hours"
patterns = ["Pattern-DOCS-001", "Pattern-IMPROVEMENT-001"]
dependencies = ["JEPA-001"]

# ------------------------------------------------------------------------------
# Mac Compatibility Tasks (1 task - Fix terminal hardcoding)
# ------------------------------------------------------------------------------

[tasks.MAC-001]
id = "MAC-001"
name = "Fix terminal creation - Remove PowerShell hardcoding for Mac compatibility"
status = "completed"
phase = "mac-compatibility"
agent = "ui-agent"

why = """
User-reported issue: Extension failing on macOS.
Current state: voicePanel.ts hardcodes 'powershell.exe' for terminal creation (line 1063).
Impact: Mac users get errors because PowerShell doesn't exist on Mac by default.
Root cause: Windows-only shell path hardcoded, not platform-agnostic.
Without this: Extension unusable on Mac (cannot create Ã†therLight terminal).
With this: Cross-platform terminal creation, works on Windows, Mac, Linux.
"""

context = """
Problem Location: vscode-lumina/src/commands/voicePanel.ts:1063

Current code:
```typescript
aetherlightTerminal = vscode.window.createTerminal(<
    name: 'Ã†therLight Claude',
    shellPath: 'powershell.exe',  // âŒ Windows-only, breaks on Mac
    shellArgs: [
        '-NoExit',
        '-Command',
        '& < Write-Host "Ã†therLight Terminal Ready ðŸŽ¤" -ForegroundColor Cyan >'
    ],
    location: vscode.TerminalLocation.Editor
>);
```

Issue: On Mac, 'powershell.exe' doesn't exist â†’ Terminal creation fails

Solution: Remove shellPath, let VS Code use default shell (cross-platform)

Correct approach (used elsewhere in codebase):
- spawner.ts:74 âœ… No shellPath specified
- PromptTerminalManager.ts:47 âœ… No shellPath specified
- updateChecker.ts:211 âœ… No shellPath specified

VS Code automatically selects correct shell:
- Windows: PowerShell, CMD, or user's configured shell
- Mac: zsh, bash, or user's configured shell
- Linux: bash, zsh, or user's configured shell

Historical context:
- Line 4707: Code already detects /^powershell$/i pattern for terminal name
- Detection works regardless of shellPath hardcoding
- Hardcoding adds no value, only breaks cross-platform compatibility
"""

reasoning_chain = [
    "1. User tries to open Ã†therLight on Mac",
    "2. Extension tries to create terminal with shellPath: 'powershell.exe'",
    "3. Mac doesn't have powershell.exe â†’ Terminal creation fails",
    "4. Extension shows error or blank terminal",
    "5. User cannot use voice-to-terminal features",
    "6. Fix: Remove shellPath, let VS Code pick correct shell",
    "7. VS Code selects zsh/bash on Mac, PowerShell on Windows automatically",
    "8. Terminal works correctly on all platforms"
]

pattern_context = "Pattern-CODE-001: Code workflow, Pattern-COMPAT-001: Cross-platform compatibility"

success_impact = """
After MAC-001 complete:
âœ… Ã†therLight terminal works on macOS (zsh/bash)
âœ… Ã†therLight terminal still works on Windows (PowerShell/CMD)
âœ… Ã†therLight terminal works on Linux (bash/zsh)
âœ… Respects user's configured default shell
âœ… Cross-platform compatible extension
âœ… Mac users can use voice-to-terminal features
"""

test_requirements = """
TDD Requirements (UI Task - 70% coverage):

Manual Testing Required (Cross-platform verification):
1. Windows: Verify terminal creates with PowerShell (default)
2. Mac: Verify terminal creates with zsh/bash (default)
3. Linux: Verify terminal creates with bash/zsh (default)
4. Custom shell: Verify respects user's configured shell
5. Terminal name: Verify 'Ã†therLight Claude' appears correctly
6. Terminal location: Verify appears in Editor area (not Panel)

Automated Testing (if possible):
1. Mock vscode.window.createTerminal() in test
2. Verify shellPath is undefined (not hardcoded)
3. Verify name and location are correct
"""

test_files = [
    "vscode-lumina/test/commands/voicePanel.test.ts"
]

test_coverage_requirement = 0.7

validation_criteria = [
    "shellPath removed from createTerminal() call",
    "Terminal creation works on Mac (zsh/bash)",
    "Terminal creation still works on Windows (PowerShell)",
    "Terminal name 'Ã†therLight Claude' correct",
    "Terminal appears in Editor location",
    "No platform-specific shell hardcoding",
    "Code follows pattern from spawner.ts and PromptTerminalManager.ts"
]

estimated_lines = -10
estimated_time = "15-30 minutes"

files_to_modify = [
    "vscode-lumina/src/commands/voicePanel.ts (lines 1061-1070 - remove shellPath and shellArgs)"
]

deliverables = [
    "Platform-agnostic terminal creation",
    "shellPath removed (let VS Code auto-select)",
    "shellArgs removed (platform-specific PowerShell command)",
    "Terminal works on Windows, Mac, Linux",
    "Manual testing on Mac confirmed working"
]

error_handling = """
- Remove shellPath entirely (don't set to undefined, just omit)
- Remove shellArgs entirely (platform-specific)
- Let VS Code handle shell selection (cross-platform)
- If terminal creation fails: VS Code handles error messaging
- Fallback: User can manually create terminal if needed
"""

performance_target = "Terminal creation < 100ms (no change from current)"
patterns = ["Pattern-CODE-001", "Pattern-COMPAT-001"]
dependencies = []

# ==============================================================================
# END OF SPRINT
# ==============================================================================
