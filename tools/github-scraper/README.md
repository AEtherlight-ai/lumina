# GitHub Repository Scraper - Node 1 Deployment Sprint 2

**VERSION:** 1.0.0
**STATUS:** Ready for Sprint 2 (Week 2-3, Days 8-21)
**PATTERN:** Pattern-SCRAPER-001 (Quality-First Repository Selection)

---

## Purpose

**DESIGN DECISION:** Quality-first repository scraping for Node 1 pattern library
**WHY:** High-quality patterns require high-quality source code with Chain of Thought reasoning

**REASONING CHAIN:**
1. GitHub has 1M+ repos, but 99% lack quality docstrings
2. Need 1,000 high-quality patterns (500 Marketing, 500 Legal)
3. Apply strict quality filters: stars >100, docstrings >40%, recent commits
4. Domain-specific search queries target relevant repos
5. Store ALL repos (passed + failed) for iteration
6. Result: 1,000+ quality repos ready for Sprint 3 pattern extraction

**IMPACT:**
- **Target:** 1,000 repos scraped in 3-4 hours
- **Quality:** >80% pass rate (validated in Sprint 2)
- **Cost:** $0 (GitHub API free for authenticated users)
- **Network Ready:** Foundation for pattern extraction (Sprint 3-4)

---

## Features

### 1. GitHub API Integration
- **Octokit** with throttling + retry plugins
- Rate limit handling (5,000 req/hour authenticated)
- Exponential backoff on errors
- Pagination support (100 repos per page)

### 2. Quality Filters
- **Stars:** >100 (popular repos)
- **Docstring Density:** >40% (estimated)
- **Recent Commits:** <90 days (active maintenance)
- **Languages:** Python, JavaScript, TypeScript
- **Size:** 100KB - 100MB (avoid toy projects and monorepos)

### 3. Domain-Specific Search
- **Marketing:** Data analytics, identity graphing, customer segmentation, ML modeling
- **Legal:** Case management, document parsing, contract analysis, timeline extraction

### 4. Comprehensive Metadata
- Language distribution
- Stars, forks, watchers
- Commit frequency
- Domain keyword matching
- Quality filter pass/fail + rejection reasons

### 5. Supabase Storage
- Store ALL repos (passed + failed)
- Batch inserts (100 at a time)
- Upsert support (resume failed runs)
- Statistics and analytics

---

## Installation

```bash
# Clone repository
cd tools/github-scraper

# Install dependencies
npm install

# Copy environment variables
cp .env.example .env

# Edit .env with your credentials
# - GITHUB_TOKEN: https://github.com/settings/tokens
# - SUPABASE_URL: https://app.supabase.com/project/_/settings/api
# - SUPABASE_SERVICE_ROLE_KEY: (same page)
```

---

## Database Setup

**Before running scraper, create `repositories` table in Supabase:**

```sql
-- Repositories table
CREATE TABLE repositories (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  owner VARCHAR(255) NOT NULL,
  name VARCHAR(255) NOT NULL,
  full_name VARCHAR(255) UNIQUE NOT NULL,
  description TEXT,
  url VARCHAR(500) NOT NULL,
  stars INTEGER NOT NULL,
  forks INTEGER NOT NULL,
  language VARCHAR(50),
  languages JSONB,
  topics TEXT[],
  created_at TIMESTAMPTZ NOT NULL,
  updated_at TIMESTAMPTZ NOT NULL,
  pushed_at TIMESTAMPTZ NOT NULL,
  size_kb INTEGER NOT NULL,
  default_branch VARCHAR(100),
  license VARCHAR(50),
  has_wiki BOOLEAN,
  has_issues BOOLEAN,
  open_issues_count INTEGER,
  watchers_count INTEGER,
  docstring_density DECIMAL(3,2),
  commit_frequency DECIMAL(5,2),
  last_commit_days_ago INTEGER NOT NULL,
  domain VARCHAR(50) NOT NULL,
  domain_keywords_matched TEXT[],
  scraped_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),
  passes_quality_filters BOOLEAN NOT NULL,
  rejection_reasons TEXT[]
);

-- Indexes for fast queries
CREATE INDEX idx_repositories_domain ON repositories(domain);
CREATE INDEX idx_repositories_quality ON repositories(passes_quality_filters);
CREATE INDEX idx_repositories_scraped_at ON repositories(scraped_at);
CREATE INDEX idx_repositories_stars ON repositories(stars DESC);
CREATE INDEX idx_repositories_language ON repositories(language);
```

---

## Usage

### Basic Usage (Both Domains)

```bash
# Build TypeScript
npm run build

# Run scraper (both Marketing + Legal)
npm run scrape
```

**Expected Output:**
```
üöÄ Starting Node 1 Deployment Sprint 2: GitHub Repository Scraping
================================================================================

üìä Step 1/5: Scraping Marketing Domain Repositories
Target: 500 repositories
Quality filters:
   - Stars: >100
   - Languages: Python, JavaScript, TypeScript
   - Recent commits: <90 days
   - Docstring density: >40%

üîç Searching: data analytics language:python stars:>100 pushed:>2024-01-01
   ‚úÖ Found 85 repos (85 total)
   üìä Rate limit: 4915 / 5000 (resets at 3:45:12 PM)

... (6 more queries)

üìä Marketing Domain Results:
   Total scraped: 520
   Passed: 450 (87%)
   Failed: 70 (13%)

‚öñÔ∏è  Step 2/5: Scraping Legal Domain Repositories
... (similar output)

üíæ Step 3/5: Storing Repositories in Supabase
   ‚úÖ Batch 1 stored (100 repos)
   ‚úÖ Batch 2 stored (100 repos)
   ... (10 batches)

üìà Step 4/5: Generating Sprint 2 Statistics
üìä Repository Statistics:
   Total: 1000
   Passed quality filters: 850 (85%)
   Failed quality filters: 150 (15%)
   Marketing domain: 450
   Legal domain: 400

   By Language:
      Python: 650
      JavaScript: 200
      TypeScript: 150

   Top Rejection Reasons:
      stars (50) < 100: 60 repos
      last commit 120 days ago > 90: 45 repos
      docstring density (0.3) < 0.4: 30 repos

üì§ Step 5/5: Exporting to JSON
   ‚úÖ Exported Marketing repos to ./output/sprint-2/marketing-repos.json
   ‚úÖ Exported Legal repos to ./output/sprint-2/legal-repos.json
   ‚úÖ Exported 850 quality repos to ./output/sprint-2/repos-passed-quality.json

üìÑ Sprint 2 report generated: ./output/sprint-2/SPRINT_2_REPORT.md

================================================================================
üéâ Sprint 2 Complete!
   Duration: 187 minutes
   Total repos scraped: 1000
   Passed quality filters: 850 (85%)
   Ready for Sprint 3: Pattern Extraction
================================================================================
```

---

### Domain-Specific Scraping

```bash
# Marketing only
npm run scrape:marketing

# Legal only
npm run scrape:legal
```

---

### Programmatic Usage

```typescript
import { ScraperOrchestrator, ScraperConfig } from '@aetherlight/github-scraper';

const config: ScraperConfig = {
  githubToken: process.env.GITHUB_TOKEN!,
  supabaseUrl: process.env.SUPABASE_URL!,
  supabaseKey: process.env.SUPABASE_SERVICE_ROLE_KEY!,
  marketingRepoTarget: 500,
  legalRepoTarget: 500,
  outputDir: './output/sprint-2',
  exportJSON: true,
};

const orchestrator = new ScraperOrchestrator(config);
await orchestrator.run();
```

---

## Configuration

### Quality Filters (Customizable)

```typescript
import { DEFAULT_QUALITY_FILTERS } from './github-api-client';

// Customize filters
const customFilters = {
  ...DEFAULT_QUALITY_FILTERS,
  min_stars: 50,              // Lower threshold
  min_docstring_density: 0.3, // Lower threshold
  max_days_since_commit: 120, // More lenient
};
```

### Domain Search Queries (Customizable)

```typescript
import { MARKETING_DOMAIN_CONFIG } from './github-api-client';

// Add custom queries
const customConfig = {
  ...MARKETING_DOMAIN_CONFIG,
  queries: [
    ...MARKETING_DOMAIN_CONFIG.queries,
    "marketing automation language:python stars:>100",
    "email campaign language:python stars:>100",
  ],
};
```

---

## Output Files

### 1. `marketing-repos.json`
All Marketing repos scraped (passed + failed)

### 2. `legal-repos.json`
All Legal repos scraped (passed + failed)

### 3. `repos-passed-quality.json`
Only repos that passed quality filters (input for Sprint 3)

### 4. `SPRINT_2_REPORT.md`
Comprehensive Sprint 2 completion report with:
- Metrics (target vs actual, pass rate)
- Language distribution
- Rejection reasons
- Next steps for Sprint 3

---

## Sprint 2 Acceptance Criteria

**From NODE1_DEPLOYMENT_SPRINT.md:**

- [x] GitHub API respects rate limits (5,000 requests/hour)
- [x] Marketing repos match domain criteria
- [x] Legal repos match domain criteria
- [x] Quality filters reject low-quality repos
- [x] Metadata stored for future pattern attribution
- [ ] >80% of scraped repos pass quality threshold (validated during run)

---

## Performance

### Typical Run (1,000 repos)

- **Duration:** 3-4 hours
- **API Requests:** ~2,000 (search + metadata)
- **Rate Limit:** 5,000 req/hour (plenty of headroom)
- **Storage:** ~2s per 100 repos (10 batches)
- **Output Size:** ~5MB JSON files

### Bottlenecks

1. **GitHub API rate limit:** 5,000 req/hour (can scrape ~10,000 repos/hour)
2. **Language API calls:** 1 per repo (adds 1,000 requests)
3. **Network latency:** ~100ms per request

### Optimizations (Future)

- **Parallel domain scraping:** 2√ó faster (Marketing + Legal simultaneously)
- **Cache language data:** Avoid redundant API calls
- **Use GraphQL API:** Fetch metadata + languages in single request

---

## Troubleshooting

### Rate Limit Exceeded

**Error:** `403 - rate limit exceeded`

**Solution:** Wait for rate limit reset (shown in logs) or use multiple GitHub tokens

```typescript
// Rotate tokens (future enhancement)
const tokens = [token1, token2, token3];
```

### Supabase Storage Errors

**Error:** `Database error: duplicate key value violates unique constraint`

**Solution:** This is expected (upsert on conflict). Repos are updated, not duplicated.

### Low Pass Rate (<80%)

**Error:** Only 60% of repos pass quality filters

**Solution:** Lower quality thresholds in config:
```typescript
const customFilters = {
  min_stars: 50,              // Lower from 100
  min_docstring_density: 0.3, // Lower from 0.4
  max_days_since_commit: 120, // Increase from 90
};
```

---

## Next Steps (Sprint 3-4)

**After Sprint 2 complete, proceed to Sprint 3-4:**

### Sprint 3-4: Pattern Extraction & Validation (Week 4-5)

**Input:** 850+ quality repositories (from `repos-passed-quality.json`)

**Output:** 1,000 patterns with Chain of Thought reasoning

**Tasks:**
1. **Day 22-23:** AST parser (Tree-sitter for Python/JS/TS)
2. **Day 24-26:** Docstring quality scorer (validate >0.7 threshold)
3. **Day 27-29:** Pattern extraction (function-level chunks)
4. **Day 30-32:** Chain of Thought inference (GPT-4o adds reasoning)
5. **Day 33-34:** Human validation (10% sample, >95% approval)
6. **Day 35:** Sprint review

**See:** `PHASE_NODE1_DEPLOYMENT.md` for Sprint 3-4 details

---

## Architecture

### Data Flow

```
GitHub API ‚Üí Quality Filters ‚Üí Supabase ‚Üí Pattern Extraction (Sprint 3)
    ‚Üì              ‚Üì              ‚Üì
  Search      Pass/Fail      Store ALL
  Metadata    Reasons        (for iteration)
```

### Components

1. **GitHubAPIClient** - Octokit wrapper with rate limiting
2. **SupabaseStorage** - Batch storage with upsert
3. **ScraperOrchestrator** - Main workflow coordinator

### Patterns Applied

- **Pattern-SCRAPER-001:** Quality-First Repository Selection
- **Pattern-STORAGE-002:** Comprehensive Metadata Storage
- **Pattern-ORCHESTRATOR-002:** Domain-Parallel Scraping

---

## Related Documents

- **PHASE_NODE1_DEPLOYMENT.md** - Complete 8-week deployment plan
- **NODE1_DEPLOYMENT_SPRINT.md** - Sprint breakdown (Sprints 1-7)
- **TRAINING_STRATEGY_OPTIMAL.md** - Voyage-3-large embedding strategy
- **EMBEDDING_STRATEGY_DECISION.md** - Hybrid search architecture

---

## License

MIT License - √ÜtherLight Team

---

**STATUS:** Sprint 2 Ready ‚úÖ
**NEXT:** Run scraper (3-4 hours) ‚Üí Generate report ‚Üí Proceed to Sprint 3
**OWNER:** Core team
**CLASSIFICATION:** üîê INTERNAL ONLY
